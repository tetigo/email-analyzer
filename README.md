# ğŸ“§ AutoU â€” Classificador de Emails

Um sistema fullstack para **classificaÃ§Ã£o automÃ¡tica de emails** e **geraÃ§Ã£o de respostas sugeridas**.

- âš¡ Backend em **FastAPI** (Python)
- ğŸ¨ Frontend em **React (Vite)**
- ğŸ¤– ClassificaÃ§Ã£o inicial com **scikit-learn**
- âœ¨ SugestÃµes de resposta via **OpenAI API** (ou templates locais se nÃ£o houver chave)


## - [Visite o App Online](https://email-analyzer-ten.vercel.app/)

---

## ğŸš€ Funcionalidades

- Upload de arquivo **.txt** ou **.pdf** (ou colar texto direto)
- ClassificaÃ§Ã£o do email como **Produtivo** ou **Improdutivo**
- Retorno de **confianÃ§a (%)** do classificador
- GeraÃ§Ã£o de **resposta sugerida**
  - Se **OPENAI_API_KEY** estiver configurada â†’ resposta gerada por LLM
  - Se **nÃ£o houver chave** â†’ usa **templates locais**
- AÃ§Ãµes rÃ¡pidas:
  - Copiar resposta para Ã¡rea de transferÃªncia
  - Baixar resposta em arquivo `.txt`

<img src="image.png" alt="app" width="600"/>


---

## ğŸ› ï¸ Stack

### Backend
- Python 3.10+
- FastAPI
- scikit-learn
- nltk
- pdfminer.six
- openai

### Frontend
- React (Vite)
- CSS simples (sem frameworks externos)

---

## ğŸ“‚ Estrutura do Projeto

```bash
autou-case/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py # API principal (FastAPI)
â”‚ â”œâ”€â”€ classifier.py # Modelo ML simples (TF-IDF + LogisticRegression)
â”‚ â”œâ”€â”€ nlp_utils.py # PrÃ©-processamento de texto (NLTK)
â”‚ â”œâ”€â”€ openai_client.py # IntegraÃ§Ã£o com OpenAI (ou fallback local)
â”‚ â””â”€â”€ requirements.txt # DependÃªncias Python
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ App.jsx
â”‚ â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”‚ â””â”€â”€ EmailForm.jsx
â”‚ â”‚ â””â”€â”€ style.css
â”‚ â”œâ”€â”€ index.html
â”‚ â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

---

## âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### ğŸ”¹ 1. Backend (FastAPI)

1. Entre na pasta:
   ```bash
   cd backend
   ```


2. Crie e ative um ambiente virtual:
   ```bash
    python -m venv venv
    source venv/bin/activate   # Linux/Mac
    venv\Scripts\activate      # Windows (PowerShell)
    ```


3. Instale as dependÃªncias:
   ```bash
    pip install -r requirements.txt
    ```


3. Instale as dependÃªncias:
   ```bash
    pip install -r requirements.txt
    ```


4. (Opcional) Configure a variÃ¡vel de ambiente OPENAI_API_KEY:
   ```bash
    export OPENAI_API_KEY=sk-xxxxxxx   # Linux/Mac
    setx OPENAI_API_KEY "sk-xxxxxxx"   # Windows
    ```


5. Rode o servidor:
   ```bash
    uvicorn main:app --reload
    ```

## ğŸš€ Servidor ativo em:

ğŸ‘‰ http://localhost:8000

---

### ğŸ”¹ 2. Frontend (React)

1. Entre na pasta:
   ```bash
   cd frontend
   ```


2. Instale dependÃªncias:
   ```bash
   npm install
   ```


3. Crie um arquivo .env na raiz do frontend:
   ```bash
   VITE_API_URL=http://localhost:8000
   ```


4. Rode o app:
   ```bash
   npm run dev
   ```


4. Rode o app:
   ```bash
   npm run dev
   ```

## ğŸš€ Frontend ativo em:

ğŸ‘‰ http://localhost:5173

---


## ğŸ§  Funcionamento

1. O usuÃ¡rio envia um email (texto colado ou arquivo `.pdf`/`.txt`).
2. O **frontend** envia o conteÃºdo para o **backend** via `POST /api/process-email`.
3. O **backend** executa:
   - **ExtraÃ§Ã£o de texto** (com `pdfminer` para PDFs).
   - **PrÃ©-processamento** (`nlp_utils` usando `nltk`).
   - **ClassificaÃ§Ã£o** (`classifier.py` com Logistic Regression).
   - **GeraÃ§Ã£o de sugestÃ£o** (`openai_client.py`):
     - Se houver **API Key** â†’ usa **OpenAI GPT**.
     - Se **nÃ£o houver API Key** â†’ usa **respostas prontas (templates)**.
4. O resultado (**categoria + confianÃ§a + resposta sugerida**) volta para o frontend.
5. O usuÃ¡rio pode **copiar** ou **baixar** a resposta.

---

## ğŸ“ Exemplo de uso

### Entrada:

 #### Prezados, gostaria de solicitar a atualizaÃ§Ã£o do pedido 123 com urgÃªncia.


### SaÃ­da (sem API Key):

#### Categoria: Produtivo (87%)
#### Resposta sugerida:
#### 
#### OlÃ¡,
#### 
#### Obrigado pelo contato. Recebemos sua solicitaÃ§Ã£o e jÃ¡ estamos analisando.
#### Em atÃ© 2 dias Ãºteis retornaremos com uma posiÃ§Ã£o mais detalhada.
#### 
#### Atenciosamente,
#### Equipe



---

## ğŸ“¦ Deploy

- O **backend** pode ser publicado em qualquer serviÃ§o que rode Python (Heroku, Render, Railway, etc.).
- O **frontend** pode ser buildado e hospedado no Vercel, Netlify ou GitHub Pages:

```bash
npm run build
```

---


## ğŸ‘¨â€ğŸ’» Autor

**Tiago Mendes** â€” Desenvolvido como case tÃ©cnico **AutoU**.





